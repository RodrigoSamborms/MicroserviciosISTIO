# Gu√≠a: Entender e Interpretar los Dashboards

Esta gu√≠a te ayuda a familiarizarte con **Kiali**, **Jaeger** y **Grafana** para observar y entender el comportamiento de los microservicios durante las pruebas de inyecci√≥n de fallos.

---

## 1. Acceder a los Dashboards

Desde PowerShell, con minikube corriendo:

```powershell
wsl -d Debian bash -lc "cd /mnt/c/Users/sambo/Documents/Programacion/GitHub/MicroserviciosISTIO && ./scripts/microservicios start"
```

Se abrir√°n autom√°ticamente en una ventana dedicada del navegador:
- **Kiali**: http://wsl.localhost:20001/kiali/console
- **Jaeger**: http://wsl.localhost:16686
- **Grafana**: http://wsl.localhost:3000

---

## 2. KIALI - Visualizaci√≥n de Topolog√≠a y Tr√°fico

### ¬øQu√© es Kiali?
Es la **interfaz visual de Istio** que muestra:
- La topolog√≠a de servicios (qu√© servicios se comunican entre s√≠)
- El flujo de tr√°fico en tiempo real
- Tasas de error y latencia
- Alertas de problemas

### C√≥mo Usar Kiali

#### Paso 1: Navegar al Graph
1. En el men√∫ izquierdo, haz clic en **Graph**
2. En el dropdown de namespace, selecciona **default**
3. Ver√°s la topolog√≠a de tus microservicios

#### Paso 2: Entender la Topolog√≠a
Ves 3 nodos principales:
- **istio-ingressgateway** (entrada desde Internet)
- **microservicio-usuarios** (tu API principal)
- **microservicio-notificaciones** (servicio interno)

Las flechas indican el flujo de tr√°fico (qui√©n llama a qui√©n).

#### Paso 3: Observar M√©tricas en Tiempo Real

Mientras ejecutas peticiones (ver secci√≥n 5 m√°s abajo), ver√°s:

**En las flechas (conexiones):**
- Grosor de la l√≠nea = volumen de tr√°fico
- Color de la l√≠nea:
  - **Verde**: Tr√°fico exitoso (2xx/3xx)
  - **Rojo**: Errores (4xx/5xx)
  - **Naranja**: Latencia alta o timeouts

**N√∫meros sobre las flechas:**
- Peticiones por segundo (req/s)
- Ejemplo: `5 req/s` significa 5 peticiones/segundo

**En los nodos (servicios):**
- Puedes ver el nombre del pod dentro
- Icono de error si hay problemas

#### Paso 4: Hacer Click en una Conexi√≥n
Si haces clic en una flecha, ves:
- **Traffic Distribution**: Porcentaje de tr√°fico que llega a cada destino
- **Response Times (quantiles)**:
  - `p50`: El 50% de peticiones responden en este tiempo
  - `p95`: El 95% de peticiones responden en este tiempo
  - `p99`: El 99% de peticiones responden en este tiempo
- **Error Rate**: % de peticiones que fallaron
- **Request Rate**: Peticiones por segundo

#### Paso 5: Configurar la Vista
En la parte superior derecha hay opciones:
- **Time Range**: Cambiar el per√≠odo de tiempo (1m, 5m, 15m, etc.)
- **Refresh Rate**: Velocidad de actualizaci√≥n (auto, pausado, etc.)
- **Metric Type**: Cambiar entre Request Rate, Error Rate, Response Time

### Interpretando Resultados de Fault Injection en Kiali

#### Escenario 1: Inyecci√≥n de Delays (5 segundos al 50%)

**Qu√© esperas ver:**
- L√≠nea normal entre istio-ingressgateway ‚Üí microservicio-usuarios (sin cambios)
- L√≠nea de microservicio-usuarios ‚Üí microservicio-notificaciones:
  - Color normal o ligeramente naranja (latencia aumentada)
  - Los n√∫meros bajo Response Time (p95, p99) subir√°n a ~5000ms (5 segundos)

**Ejemplo de lectura:**
```
Conexi√≥n: usuarios ‚Üí notificaciones
‚îú‚îÄ Request Rate: 10 req/s
‚îú‚îÄ Error Rate: 0%
‚îî‚îÄ Response Time (p95): 5234ms  ‚Üê ¬°AUMENT√ì DE ~100ms A ~5000ms!
```

**Lo que significa:**
- Las peticiones siguen llegando (0% error)
- Pero la mitad tiene un delay artificial de 5 segundos
- El p95 sube porque el 95% de peticiones sufren este delay

#### Escenario 2: Inyecci√≥n de Errores (503 al 30%)

**Qu√© esperas ver:**
- L√≠nea de microservicio-usuarios ‚Üí microservicio-notificaciones:
  - **ROJA** (indica errores)
  - El Error Rate mostrar√° ~30%

**Ejemplo de lectura:**
```
Conexi√≥n: usuarios ‚Üí notificaciones
‚îú‚îÄ Request Rate: 10 req/s
‚îú‚îÄ Error Rate: 30%  ‚Üê ¬°Aparecen errores!
‚îî‚îÄ Response Time (p50): 50ms  ‚Üê R√°pidos porque fallan antes
```

**Lo que significa:**
- 3 de cada 10 peticiones fallan con error 503
- El tiempo es r√°pido porque Istio rechaza la petici√≥n antes de llegar al servicio
- La l√≠nea est√° roja porque hay errores

#### Escenario 3: Combinado (Delays 30% + Errores 20%)

**Qu√© esperas ver:**
- L√≠nea ROJA (por los errores)
- Response Time (p95) alto (~3000ms por delays)
- Error Rate ~20%

**Lectura combinada:**
```
Conexi√≥n: usuarios ‚Üí notificaciones
‚îú‚îÄ Request Rate: 10 req/s
‚îú‚îÄ Error Rate: 20%  ‚Üê Algunos errores
‚îî‚îÄ Response Time (p95): 3156ms  ‚Üê Latencia aumentada
```

---

## 3. JAEGER - Trazas Distribuidas

### ¬øQu√© es Jaeger?
Es el **rastreador de trazas distribuidas**. Muestra:
- El viaje completo de UNA petici√≥n a trav√©s de todos los servicios
- Tiempos de cada operaci√≥n
- Errores en puntos espec√≠ficos

### C√≥mo Usar Jaeger

#### Paso 1: Acceder a Jaeger
Ve a http://wsl.localhost:16686

#### Paso 2: Buscar Trazas
1. En el men√∫ izquierdo, selecciona:
   - **Service**: `microservicio-usuarios` (o `istio-ingressgateway`)
   - **Operation**: Deja el default o selecciona una operaci√≥n
2. Haz clic en **Find Traces**

#### Paso 3: Entender una Traza
Ver√°s una lista de trazas. Cada una es el viaje de UNA petici√≥n. Click en una:

**Informaci√≥n en la traza:**
- **Timeline**: L√≠nea horizontal mostrando el tiempo total
- **Spans**: Cuadros que representan operaciones en cada servicio
  - El grosor/tama√±o = cu√°nto tiempo tom√≥ esa operaci√≥n
- **Duraci√≥n**: Tiempo total de la petici√≥n

**Ejemplo de traza normal (~100ms):**
```
GET /usuarios (total: 100ms)
‚îú‚îÄ istio-ingressgateway: 5ms
‚îî‚îÄ microservicio-usuarios: 95ms
   ‚îî‚îÄ Query DB: 90ms
```

**Ejemplo de traza con DELAY (~5100ms):**
```
POST /usuarios (total: 5100ms)
‚îú‚îÄ istio-ingressgateway: 5ms
‚îî‚îÄ microservicio-usuarios: 5095ms
   ‚îú‚îÄ Call notificaciones: 5000ms  ‚Üê ¬°DELAY INJECTED!
   ‚îî‚îÄ Guardar en DB: 95ms
```

**Ejemplo de traza con ERROR:**
```
POST /usuarios (total: 50ms)  [ERROR]
‚îú‚îÄ istio-ingressgateway: 5ms
‚îî‚îÄ microservicio-usuarios: 45ms
   ‚îú‚îÄ Call notificaciones: 40ms  [ERROR: 503]
   ‚îî‚îÄ Retry: (no ocurri√≥)
```

### Interpretando Errores en Jaeger

Busca **Spans rojos** (indican error):
- Haz click en el span rojo
- En el panel derecho ver√°s:
  - `error: true`
  - Mensaje de error (ej: "503 Service Unavailable")
  - Stack trace si est√° disponible

---

## 4. GRAFANA - M√©tricas Hist√≥ricas

### ¬øQu√© es Grafana?
Es la **base de datos de m√©tricas hist√≥ricas**. Muestra:
- Gr√°ficos de l√≠nea con tendencias
- Promedio, m√°ximo, m√≠nimo de m√©tricas
- Alertas configuradas

### C√≥mo Usar Grafana

#### Paso 1: Acceder
Ve a http://wsl.localhost:3000
- Usuario: `admin`
- Contrase√±a: `admin`

#### Paso 2: Ir a Dashboards
1. Click en el icono de **Dashboards** (4 cuadros) en el men√∫ izquierdo
2. Selecciona **Istio Service Dashboard**

#### Paso 3: Entender el Dashboard
Ver√°s varios gr√°ficos. Los m√°s importantes:

**Request Volume (Volumen de Peticiones):**
- Eje Y: Peticiones por segundo
- Eje X: Tiempo
- L√≠nea ascendente = m√°s tr√°fico
- L√≠nea plana = sin tr√°fico

**Error Rate (Tasa de Errores):**
- Eje Y: Porcentaje (0-100%)
- Un pico = momento en que ocurrieron errores
- Sin l√≠nea = 0% errores

**Response Time (Tiempo de Respuesta):**
- Eje Y: Milisegundos
- Pico alto = peticiones lentgas
- L√≠nea plana = respuestas r√°pidas consistentes

**Request Duration (Duraci√≥n de Peticiones) - Histograma:**
- Muestra la distribuci√≥n:
  - Cu√°ntas peticiones tardaron 0-50ms
  - Cu√°ntas tardaron 50-100ms
  - Cu√°ntas tardaron 100-500ms
  - Etc.

### Interpretando Resultados en Grafana

#### Antes de Inyecci√≥n de Fallos:
```
Request Volume: l√≠nea plana ~10 req/s
Error Rate: l√≠nea plana 0%
Response Time: l√≠nea plana ~50ms
```

#### Durante Inyecci√≥n de DELAYS (5s al 50%):
```
Request Volume: l√≠nea plana ~10 req/s (igual)
Error Rate: l√≠nea plana 0% (no hay errores, solo lentitud)
Response Time: PICO a ~5000ms  ‚Üê ¬°Aument√≥ enormemente!
```

#### Durante Inyecci√≥n de ERRORES (503 al 30%):
```
Request Volume: l√≠nea plana ~10 req/s (igual)
Error Rate: PICO a ~30%  ‚Üê ¬°Aparecen errores!
Response Time: l√≠nea plana ~50ms (r√°pidos porque fallan)
```

#### Durante Inyecci√≥n COMBINADA:
```
Request Volume: l√≠nea plana ~10 req/s (igual)
Error Rate: PICO a ~20%  ‚Üê Algunos errores
Response Time: PICO a ~3000ms  ‚Üê Latencia por delays
```

---

## 5. Gu√≠a Pr√°ctica: Ejecutar una Prueba Completa

### Paso 1: Preparar los Dashboards
```powershell
# Desde PowerShell
wsl -d Debian bash -lc "cd /mnt/c/Users/sambo/Documents/Programacion/GitHub/MicroserviciosISTIO && ./scripts/microservicios start"
```

Espera a que se abran los 3 dashboards en la ventana dedicada.

### Paso 2: Tener 3 Ventanas/Tabs Abiertas
- Tab 1: **Kiali** (http://wsl.localhost:20001/kiali/console)
  - Navega a Graph ‚Üí namespace default
- Tab 2: **Jaeger** (http://wsl.localhost:16686)
  - Service: microservicio-usuarios
- Tab 3: **Grafana** (http://wsl.localhost:3000)
  - Abre Istio Service Dashboard

### Paso 3: Aplicar Inyecci√≥n de Delays
```bash
# Desde WSL (nueva terminal)
cd /mnt/c/Users/sambo/Documents/Programacion/GitHub/MicroserviciosISTIO
kubectl apply -f k8s/fault-injection-delay.yaml

# Espera 5 segundos para que Istio propague
sleep 5
```

### Paso 4: Generar Tr√°fico
```bash
# Desde WSL
for i in {1..20}; do
  echo "Petici√≥n $i:"
  time curl -s -X POST http://$(minikube ip):31769/usuarios \
    -H "Content-Type: application/json" \
    -d "{\"nombre\":\"Test$i\"}" | head -c 100
  echo ""
  sleep 0.5
done
```

### Paso 5: Observar en Tiempo Real

**En Kiali:**
- La l√≠nea usuarios ‚Üí notificaciones debe estar NARANJA
- Los n√∫meros deben mostrar p95 ~5000ms
- Error Rate debe seguir siendo 0%

**En Grafana:**
- Response Time debe tener un PICO a ~5000ms
- Error Rate debe estar en 0%

**En Jaeger:**
- Busca nuevas trazas (click "Find Traces")
- Algunas trazas mostrar√°n Call notificaciones ~5000ms
- Otras mostrar√°n ~100ms (las que no fueron afectadas por el delay)

### Paso 6: Limpiar
```bash
# Desde WSL
kubectl delete -f k8s/fault-injection-delay.yaml

# Espera a que se propague (5-10 segundos)
sleep 10
```

**Qu√© esperas ver ahora:**
- Kiali: L√≠nea vuelve a VERDE, p95 vuelve a ~100ms
- Grafana: Response Time vuelve a la l√≠nea plana ~50ms
- Jaeger: Las nuevas trazas muestran duraci√≥n normal ~100ms

---

## 6. Troubleshooting: Qu√© Hacer Si No Ves Cambios

### Problema 1: Los dashboards no muestran tr√°fico
**Soluci√≥n:**
```bash
# 1. Verifica que el fault injection est√© aplicado
kubectl get virtualservice -n default

# 2. Verifica que los pods est√©n listos
kubectl get pods -n default
```

### Problema 2: Kiali muestra l√≠nea ROJA aunque no inyect√© errores
**Posible causa:**
- Los pods se acaban de crear (conexiones fallando mientras inician)
- Los dashboards tardan en actualizarse

**Soluci√≥n:**
- Espera 30 segundos y recarga Kiali
- Genera m√°s tr√°fico

### Problema 3: Jaeger no muestra nuevas trazas
**Soluci√≥n:**
```bash
# 1. Busca expl√≠citamente en Jaeger:
# - Service: microservicio-usuarios
# - Operation: (default)
# - Time range: Last 5 minutes
# - Click "Find Traces"

# 2. Si a√∫n no ves nada, verifica servicios en Jaeger
# El dropdown de "Service" debe mostrar:
# - istio-ingressgateway
# - microservicio-usuarios
# - microservicio-notificaciones
```

### Problema 4: Grafana muestra m√©tricas vac√≠as
**Causa:**
- Grafana tarda 1-2 minutos en recibir las primeras m√©tricas
- Los dashboards pueden estar vac√≠os inicialmente

**Soluci√≥n:**
- Espera 2-3 minutos despu√©s de generar tr√°fico
- Recarga el dashboard (F5)
- Verifica que el rango de tiempo sea "Last 1 hour"

---

## 7. Resumen R√°pido: Qu√© Esperar en Cada Escenario

| Escenario | Kiali | Grafana Response Time | Error Rate | Jaeger |
|-----------|-------|------------------------|------------|--------|
| **Normal** | Verde, p95~100ms | L√≠nea plana ~50ms | 0% | Duraci√≥n ~100ms |
| **Delays 50% / 5s** | Naranja, p95~5000ms | Pico a ~5000ms | 0% | Algunas trazas ~5000ms |
| **Errores 30% / 503** | ROJA, p95~50ms | L√≠nea plana ~50ms | Pico 30% | Spans rojos |
| **Combinado** | ROJA, p95~3000ms | Pico latencia + error | Pico 20% | Rojo + latencia |

---

## 8. Pr√≥ximos Pasos

Una vez domines esto:
1. Experimenta con `fault-injection-abort.yaml`
2. Prueba `fault-injection-combined.yaml`
3. Observa c√≥mo cambia la topolog√≠a y las m√©tricas
4. Lee la [GUIA_INYECCION_FALLOS.md](GUIA_INYECCION_FALLOS.md) para escenarios avanzados

¬°Ahora eres capaz de interpretar correctamente los dashboards y entender el comportamiento de tus microservicios! üéâ
